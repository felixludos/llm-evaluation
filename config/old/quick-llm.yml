

#server._type: llm-server

#load_name: phi2
#load_name: gemma-2b-it
#load_name: tinystories

#generate_name: hfgen
#generate_name: hfchat


#model_id: roneneldan/TinyStories-1M
#tokenizer_id: EleutherAI/gpt-neo-125M

model_id: apple/OpenELM-270M-Instruct
tokenizer_id: meta-llama/Llama-2-7b-hf

device: cuda

4bit: no
8bit: no

model_args:
  torch_dtype: auto
#  trust_remote_code: yes
  device_map: <>device
  load_in_4bit: <>4bit
  load_in_8bit: <>8bit

tokenizer_args:
#  trust_remote_code: yes
  device_map: <>device

generate_args:
  max_new_tokens: 200
  max_time: 30
#  do_sample: yes
#  top_k: 50
#  temperature: 0.7


