
#_meta.script_name: serve
#_meta.script_name: sandbox
#_meta.script_name: submit-llm
#_meta.script_name: chat
_meta.script_name: calc

#_meta.help: yes

#endpoint._mod: toked

#_base: [local]



#task-log: /is/cluster/fleeb/log.jsonl
#working-root: /is/cluster/fleeb/tasks
#task-log: \\wsl.localhost\Ubuntu-20.04\home\fleeb\log.jsonl
#working-root: \\wsl.localhost\Ubuntu-20.04\home\fleeb\tasks



#model-id: google/gemma-2b-it


#command: source $CONDA_PREFIX/etc/profile.d/conda.sh; conda activate llm; text-generation-launcher
#command: text-generation-launcher --port {port}
#command: /home/fleeb/.cargo/bin/text-generation-launcher
#command: conda activate llm && /home/fleeb/.cargo/bin/text-generation-launcher
#command: singularity run --nv --bind singe/data:/data singe/text-generation-inference.sif

#port: 8080



###################

#_base: [quick-llm]
#
#_meta.script_name: start-server
#
##server._type: manager-server
#
#manager._type: task-manager
#
#config_root._type: default-config-root




#root: test-job-root


#4bit: yes
#8bit: no
#device: cuda
#
#model-id: microsoft/phi-2
#
#model_args:
#  trust_remote_code: yes
#  device_map: <>device
#  load_in_4bit: <>4bit
#  load_in_8bit: <>8bit
#
#tokenizer_args:
#  trust_remote_code: yes
#  device_map: <>device

